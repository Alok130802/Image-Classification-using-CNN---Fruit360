{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "fruit.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alok130802/Image-Classification-using-CNN---Fruit360/blob/master/fruit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3LN7K0ZpSZ_",
        "colab_type": "text"
      },
      "source": [
        "Import data from google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnAnhCCnORdI",
        "colab_type": "code",
        "outputId": "606d1193-880e-42c5-afc8-288073d97fef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-D3txqctpflq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1acff0e5-e039-40a6-b122-24c4e346478b"
      },
      "source": [
        "!pip install --upgrade tensorflow==2.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/0f/7bd55361168bb32796b360ad15a25de6966c9c1beb58a8e30c01c8279862/tensorflow-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (86.3MB)\n",
            "\u001b[K     |████████████████████████████████| 86.3MB 53kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.1.8)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.17.4)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.33.6)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.15.0)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 46.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (3.10.0)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 69.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.11.2)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (42.0.2)\n",
            "Collecting google-auth<2,>=1.6.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/f8/84b5771faec3eba9fe0c91c8c5896364a8ba08852c0dea5ad2025026dd95/google_auth-1.10.0-py2.py3-none-any.whl (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 12.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (4.0.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.2.7)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.1.0)\n",
            "\u001b[31mERROR: tensorboard 2.0.2 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.10.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: google-auth, tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: google-auth 1.4.2\n",
            "    Uninstalling google-auth-1.4.2:\n",
            "      Successfully uninstalled google-auth-1.4.2\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed google-auth-1.10.0 tensorboard-2.0.2 tensorflow-2.0.0 tensorflow-estimator-2.0.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2qiMUE3OHSu",
        "colab_type": "text"
      },
      "source": [
        "## Unzip fruit dataset in folder fruitdata\n",
        "\n",
        "In this cell first we will unzip our zipped fruit dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRNn8mrhOHSx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ef5ed411-cfb1-4581-9063-7a0eed315ba1"
      },
      "source": [
        "from pathlib import Path\n",
        "homedir = Path(\"./drive/My Drive/fruits.zip\")\n",
        "\n",
        "\n",
        "\n",
        "from zipfile import ZipFile\n",
        "with ZipFile(\"./drive/My Drive/fruits.zip\",'r') as zip:\n",
        "    print(\"started unziping ....\")\n",
        "    zip.extractall()\n",
        "    print(\"ended unziping ...\")\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "started unziping ....\n",
            "ended unziping ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oksiPdJWOHS1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainDir = Path('./fruits-360_dataset/fruits-360/Training')\n",
        "testDir = Path('./fruits-360_dataset/fruits-360/Test')\n",
        "listOfAllFruitsFolder = list()\n",
        "for i in trainDir.iterdir():\n",
        "    listOfAllFruitsFolder.append(i)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkO5WVH7OHTA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "tf.__version__\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4COfknsCOHTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_y04E600A4RY",
        "colab_type": "text"
      },
      "source": [
        "## create a train image generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ArFqxcYOHTI",
        "colab_type": "code",
        "outputId": "5e7e8adc-2f4a-4ac0-c2e6-699d41a5ee82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        " \n",
        "train_genertaor =tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./225)\n",
        "\n",
        "train_Dataset = train_genertaor.flow_from_directory(trainDir,target_size=(50,50),shuffle = True)\n",
        "sample_image,label = next(train_Dataset)\n",
        "img = label[0]\n",
        "print(img.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 60498 images belonging to 120 classes.\n",
            "(120,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0vhjvWOA-t0",
        "colab_type": "text"
      },
      "source": [
        "## create a model given in paper \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndOA3D4zOHTK",
        "colab_type": "code",
        "outputId": "834bf27d-ef3e-4a4a-f0f4-df9c9b9a7854",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        }
      },
      "source": [
        "## create a model given in paper \n",
        "\n",
        "model  = tf.keras.models.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(16,(5,5),padding='same',activation='relu',input_shape=(50,50,3)))\n",
        "model.add(layers.MaxPool2D(strides=2))\n",
        "model.add(layers.Conv2D(32,(5,5),padding='same',activation='relu'))\n",
        "\n",
        "model.add(layers.MaxPool2D(strides=2))\n",
        "model.add(layers.Conv2D(64,(5,5),padding='same',activation='relu'))\n",
        "model.add(layers.MaxPool2D(strides=2))\n",
        "model.add(layers.Conv2D(128,(5,5),padding='same',activation='relu'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256,activation='relu'))\n",
        "model.add(layers.Dense(120,activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 50, 50, 16)        1216      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 25, 25, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 25, 25, 32)        12832     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 12, 12, 64)        51264     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 6, 6, 128)         204928    \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 4608)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               1179904   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 120)               30840     \n",
            "=================================================================\n",
            "Total params: 1,480,984\n",
            "Trainable params: 1,480,984\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqUVS7PQBCue",
        "colab_type": "text"
      },
      "source": [
        "## Compile Model using adam as optimizer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3wzNvonOHTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.categorical_crossentropy,\n",
        "              metrics=[tf.keras.metrics.categorical_accuracy])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G45ArF7uOHTP",
        "colab_type": "code",
        "outputId": "bb772bc4-86c7-42d6-bcdc-cf8f813b98d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "epoch = 10\n",
        "history = model.fit_generator(train_Dataset,epochs=epoch )"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1891/1891 [==============================] - 543s 287ms/step - loss: 0.1428 - categorical_accuracy: 0.9564\n",
            "Epoch 2/10\n",
            "1891/1891 [==============================] - 529s 280ms/step - loss: 0.0678 - categorical_accuracy: 0.9821\n",
            "Epoch 3/10\n",
            "1891/1891 [==============================] - 515s 272ms/step - loss: 0.0416 - categorical_accuracy: 0.9885\n",
            "Epoch 4/10\n",
            "1891/1891 [==============================] - 496s 262ms/step - loss: 0.0485 - categorical_accuracy: 0.9884\n",
            "Epoch 5/10\n",
            "1891/1891 [==============================] - 496s 262ms/step - loss: 0.0321 - categorical_accuracy: 0.9919\n",
            "Epoch 6/10\n",
            "1891/1891 [==============================] - 502s 265ms/step - loss: 0.0394 - categorical_accuracy: 0.9903\n",
            "Epoch 7/10\n",
            "1891/1891 [==============================] - 511s 270ms/step - loss: 0.0338 - categorical_accuracy: 0.9923\n",
            "Epoch 8/10\n",
            "1891/1891 [==============================] - 488s 258ms/step - loss: 0.0409 - categorical_accuracy: 0.9922\n",
            "Epoch 9/10\n",
            "1891/1891 [==============================] - 464s 245ms/step - loss: 0.0426 - categorical_accuracy: 0.9922\n",
            "Epoch 10/10\n",
            "1891/1891 [==============================] - 475s 251ms/step - loss: 0.0309 - categorical_accuracy: 0.9940\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYzijib6BL3O",
        "colab_type": "text"
      },
      "source": [
        "## Save Model on disk "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoxUZ5RdOHTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('fruit_model.h5')\n",
        "new_model = tf.keras.models.load_model('fruit_model.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKoD6_llBRhQ",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oEQtJPw-KK_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "9f502a4b-3dca-48a9-bac6-12faec918163"
      },
      "source": [
        "test_genertaor =tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./225)\n",
        "\n",
        "test_Dataset = test_genertaor.flow_from_directory(testDir,target_size=(50,50),shuffle = True)\n",
        "loss,acc = new_model.evaluate_generator(test_Dataset,verbose=2)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 20622 images belonging to 120 classes.\n",
            "645/645 - 46s - loss: 0.4961 - categorical_accuracy: 0.9368\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4960996330451897, 0.936815]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSC9-IvtBzJi",
        "colab_type": "text"
      },
      "source": [
        "## At last we got the 93 % Test Accuracy"
      ]
    }
  ]
}